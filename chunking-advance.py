from langchain_community.document_loaders import PyPDFLoader
from langchain_experimental.text_splitter import SemanticChunker
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma

# ============ LOAD PDF ============
def load_pdf(file_path):
    print("ğŸ“„ Loading PDF...")
    loader = PyPDFLoader(file_path)
    documents = loader.load()
    print(f"âœ… Pages loaded: {len(documents)}")
    return documents

# ============ SEMANTIC CHUNKING ============
def semantic_chunking(documents):
    print("ğŸ§  Loading embedding model...")
    embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-small-en-v1.5"
    )

    print("âœ‚ï¸ Performing AI semantic chunking...")
    text_splitter = SemanticChunker(embeddings)
    chunks = text_splitter.split_documents(documents)
    print(f"âœ… Total chunks created: {len(chunks)}")
    return chunks, embeddings

# ============ STORE IN CHROMA VECTOR DB ============
def save_to_chroma(chunks, embeddings):
    print("ğŸ—„ Storing embeddings in ChromaDB...")
    db = Chroma.from_documents(
        chunks,
        embeddings,
        persist_directory="chroma_db"
    )
    print("âœ… Chroma Vector DB created successfully!")

# ============ MAIN ============
file_path = input("Enter PDF file path: ")

print("\nğŸ” Extracting text from PDF...")
documents = load_pdf(file_path)

print("\nğŸ§© Performing semantic chunking...")
chunks, embeddings = semantic_chunking(documents)

print("\nğŸ’¾ Saving to vector database...")
save_to_chroma(chunks, embeddings)

print("\nğŸ‰ Pipeline Complete! Your PDF is AI-ready.")




